{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec86c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = \"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\"\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"langsmith-onboarding\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c81d96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = getpass.getpass(\"LANGCHAIN_API_KEY: \")\n",
    "os.environ[\"TAVIS_API_KEY\"] = getpass.getpass(\"TAVIS_API_KEY: \")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"GROQ_API_KEY\"] = getpass.getpass(\"GROQ_API_KEY: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8f807186",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7acb540",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ChatGroq(model_name=\"llama3-8b-8192\",\n",
    "     temperature=0,api_key=os.getenv(\"GROQ_API_KEY\") \n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c6eb749",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "from langchain import hub\n",
    "from langchain.agents import create_openai_functions_agent\n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "tools = [\n",
    "    TavilySearchResults(\n",
    "        max_results=1\n",
    "    )\n",
    "]\n",
    "\n",
    "prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
    "\n",
    "llm = ChatGroq(\n",
    "    model_name=\"llama3-70b-8192\",\n",
    "    temperature=0,\n",
    "    streaming=True,\n",
    ")\n",
    "\n",
    "agent_runnable = create_openai_functions_agent(\n",
    "    llm=llm,\n",
    "    tools=tools,\n",
    "    prompt=prompt\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7116d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, Annotated, List, Union\n",
    "from langchain_core.agents import AgentAction, AgentFinish\n",
    "from langchain_core.messages import BaseMessage\n",
    "import operator\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    input: str\n",
    "    chat_history: List[BaseMessage]\n",
    "    agent_outcome: Union[AgentAction, AgentFinish, None]\n",
    "    intermediate_steps: Annotated[list[tuple[AgentAction, str]], operator.add]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dcee43c",
   "metadata": {},
   "source": [
    "Define the node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43383abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.agents import AgentFinish\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "\n",
    "\n",
    "tool_executor = ToolNode(tools)\n",
    "\n",
    "# Define the agent\n",
    "def run_agent(data):\n",
    "    agent_outcome = agent_runnable.invoke(data)\n",
    "    return {\"agent_outcome\": agent_outcome} \n",
    "\n",
    "\n",
    "\n",
    "def should_continue(data):\n",
    "    if isinstance(data[\"agent_outcome\"], AgentFinish):\n",
    "        return \"end\"\n",
    "    else:\n",
    "        return \"continue\"\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7270d9dd",
   "metadata": {},
   "source": [
    "# Define the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57f4982f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import END, StateGraph\n",
    "\n",
    "tool_node = ToolNode(tools=tools)\n",
    "\n",
    "workflow = StateGraph(AgentState)\n",
    "workflow.add_node(\"agent\", run_agent)\n",
    "workflow.add_node(\"action\", tool_node)\n",
    "workflow.set_entry_point(\"agent\")\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"agent\",\n",
    "    should_continue,\n",
    "    {\n",
    "        \"continue\": \"action\",\n",
    "        \"end\": END,\n",
    "    },\n",
    ")\n",
    "\n",
    "workflow.add_edge(\"action\", \"agent\")\n",
    "app = workflow.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d339c0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'agent_outcome': AgentFinish(return_values={'output': ''}, log='')}\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "inputs = {\"input\": \"The 1st president of America\", \"chat_history\": []}\n",
    "\n",
    "for s in app.stream(inputs):\n",
    "    print(list(s.values())[0])  \n",
    "    print(\"----\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b93d9045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full result:\n",
      "content='81 chia 9 bằng 9.' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 18, 'total_tokens': 27, 'completion_time': 0.028300789, 'prompt_time': 0.000255537, 'queue_time': 0.220509222, 'total_time': 0.028556326}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_dd4ae1c591', 'finish_reason': 'stop', 'logprobs': None} id='run--ccdb18f4-12ad-4643-bcea-d4afee2999ce-0' usage_metadata={'input_tokens': 18, 'output_tokens': 9, 'total_tokens': 27}\n",
      "Content only:\n",
      "81 chia 9 bằng 9.\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "# Create a ChatOpenAI model\n",
    "#model = ChatOpenAI(model=\"gpt-4o\")\n",
    "model = ChatGroq(model_name=\"llama3-70b-8192\",\n",
    "     temperature=0,api_key=os.getenv(\"GROQ_API_KEY\") \n",
    "     )\n",
    "result = model.invoke(\"81 chia 9 bằng bao nhiêu?\")\n",
    "print(\"Full result:\")\n",
    "print(result)\n",
    "print(\"Content only:\")\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8688c0c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LANGCHAIN_API_KEY = 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\n",
      "GROQ_API_KEY = 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\n",
      "TAVILY_API_KEY = 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\n"
     ]
    }
   ],
   "source": [
    "from dotenv import dotenv_values\n",
    "\n",
    "env_vars = dotenv_values()  # Trả về dict chỉ chứa các biến từ file .env\n",
    "for key, value in env_vars.items():\n",
    "    print(f\"{key} = {value}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
